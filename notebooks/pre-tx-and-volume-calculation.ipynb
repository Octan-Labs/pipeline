{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c031afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse, sys\n",
    "\n",
    "# parser=argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument(\"-b\", \"--base_path\", help=\"S3 bucket base path\", required=True)\n",
    "# parser.add_argument(\"-s\", \"--start\", help=\"Start date to calculate\", required=True)\n",
    "# parser.add_argument(\"-e\", \"--end\", help=\"End date to calculate\", required=True)\n",
    "# parser.add_argument(\"-n\", \"--name\", help=\"Name of chain to calculate [bsc|eth|polygon]\", required=True)\n",
    "# parser.add_argument(\"-c\", \"--cmc_id\", help=\"CMC ID 's native token to calculate [BNB=1839|ETH=1027|MATIC=3890]\", required=True)\n",
    "\n",
    "# args=parser.parse_args()\n",
    "\n",
    "# base_path = args.base_path\n",
    "# start = args.start\n",
    "# end = args.end\n",
    "# name = args.name # [bsc|eth|polygon]\n",
    "# cmc_id = args.cmc_id  # [BNB=1839|ETH=1027|MATIC=3890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36addc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \".\"\n",
    "start = \"2023-07-24\"\n",
    "end = \"2023-07-24\"\n",
    "name = \"eth\" # [bsc|eth|polygon]\n",
    "cmc_id = \"1027\" # [BNB=1839|ETH=1027|MATIC=3890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42fdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_dates_in_range(start, end):\n",
    "    # Convert start and end strings to datetime objects\n",
    "    start_date = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "\n",
    "    # Create a list to store the dates within the range\n",
    "    dates_list = []\n",
    "\n",
    "    # Loop through the dates and append them to the list\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates_list.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b453980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = get_dates_in_range(start, end)\n",
    "\n",
    "num_of_date = len(dates)\n",
    "time_range = \"\"\n",
    "\n",
    "if(num_of_date == 1):\n",
    "    time_range = \"date\"\n",
    "elif(num_of_date < 7 or num_of_date == 7):\n",
    "    time_range = \"week\"\n",
    "else:\n",
    "    time_range = \"month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61b28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46c44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DecimalType, DoubleType, TimestampType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253ee044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:06:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PreTxAndVolumeCalculator\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10f495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec358df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transfers_schema = StructType([ \\\n",
    "    StructField(\"token_address\", StringType(), True), \\\n",
    "    StructField(\"from_address\", StringType(), True), \\\n",
    "    StructField(\"to_address\", StringType(), True), \\\n",
    "    StructField(\"value\", StringType(), True), \\\n",
    "    StructField(\"transaction_hash\", StringType(), True), \\\n",
    "    StructField(\"log_index\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"block_number\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"block_timestamp\", TimestampType(), True), \\\n",
    "    StructField(\"block_hash\", StringType(), True), \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2010d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_schema = StructType([ \\\n",
    "    StructField(\"hash\", StringType(), True), \\\n",
    "    StructField(\"nonce\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"transaction_index\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"from_address\", StringType(), True), \\\n",
    "    StructField(\"to_address\", StringType(), True), \\\n",
    "    StructField(\"value\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"gas\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"gas_price\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"input\", StringType(), True), \\\n",
    "    StructField(\"block_timestamp\", TimestampType(), True), \\\n",
    "    StructField(\"block_number\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"block_hash\", StringType(), True), \\\n",
    "    StructField(\"max_fee_per_gas\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"max_priority_fee_per_gas\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"transaction_type\", LongType(), True), \\\n",
    "    StructField(\"receipt_cumulative_gas_used\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"receipt_gas_used\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"receipt_contract_address\", StringType(), True), \\\n",
    "    StructField(\"receipt_root\", StringType(), True), \\\n",
    "    StructField(\"receipt_status\", DecimalType(38, 0), True), \\\n",
    "    StructField(\"receipt_effective_gas_price\", DecimalType(38, 0), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a19283",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_schema = StructType([ \\\n",
    "    StructField(\"address\", StringType(), True), \\\n",
    "    StructField(\"symbol\", StringType(), True), \\\n",
    "    StructField(\"name\", StringType(), True), \\\n",
    "    StructField(\"decimals\", LongType(), True), \\\n",
    "    StructField(\"total_supply\", DecimalType(38,0), True), \\\n",
    "    StructField(\"block_number\", LongType(), True), \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e65627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_historical_schema = StructType([ \\\n",
    "    StructField(\"id\", LongType(), True), \\\n",
    "    StructField(\"rank\", LongType(), True), \\\n",
    "    StructField(\"open\", DoubleType(), True), \\\n",
    "    StructField(\"close\", DoubleType(), True), \\\n",
    "    StructField(\"timestamp\", LongType(), True), \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0b315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89235750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.files.ignoreCorruptFiles=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57442cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transfers_df = spark.read.format(\"parquet\") \\\n",
    "    .schema(token_transfers_schema) \\\n",
    "    .load(list(map(lambda date: \"{base_path}/token_transfers/date={date}/*.parquet\".format(base_path = base_path, date = date), dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d94c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = spark.read.format(\"parquet\") \\\n",
    "    .load(list(map(lambda date: \"{base_path}/transactions/date={date}/*.parquet\".format(base_path = base_path, date = date), dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a673251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_df = spark.read.format(\"csv\") \\\n",
    "#     .option(\"header\", True) \\\n",
    "#     .schema(tokens_schema) \\\n",
    "#     .load(\"s3a://octan-labs-bsc/cmc_tokens/cmc_{name}_tokens.csv\".format(name = name))\n",
    "# cmc_historicals_df = spark.read.format(\"csv\") \\\n",
    "#     .schema(cmc_historical_schema) \\\n",
    "#     .load(\"s3a://octan-labs-bsc/cmc_historicals/*.csv\")\n",
    "# cmc_addresses_df = spark.read.format(\"csv\") \\\n",
    "#     .option(\"header\", True) \\\n",
    "#     .schema(cmc_address_schema) \\\n",
    "#     .load(\"s3a://octan-labs-bsc/cmc_addresses/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8e6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(tokens_schema) \\\n",
    "    .load(\"{base_path}/cmc_tokens/cmc_{name}_tokens.csv\".format(base_path = base_path, name = name))\n",
    "cmc_historicals_df = spark.read.format(\"csv\") \\\n",
    "    .schema(cmc_historical_schema) \\\n",
    "    .load(\"{base_path}/cmc_historicals/*.csv\".format(base_path = base_path))\n",
    "cmc_addresses_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"{base_path}/cmc_addresses/*.csv\".format(base_path = base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab65387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64dd18ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rank: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- bsc: string (nullable = true)\n",
      " |-- eth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmc_addresses_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981c62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581ea759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_addresses_df = cmc_addresses_df.dropDuplicates([\"{name}\".format(name = name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d99517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d2e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, format_number, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c8925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = transactions_df.drop(col(\"input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73eadf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d454e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transfers_df.createOrReplaceTempView(\"token_transfers\")\n",
    "transactions_df.createOrReplaceTempView(\"transactions\")\n",
    "tokens_df.createOrReplaceTempView(\"tokens\")\n",
    "cmc_historicals_df.createOrReplaceTempView(\"cmc_historicals\")\n",
    "cmc_addresses_df.createOrReplaceTempView(\"cmc_addresses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f9a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3075118064880371"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change name, cmc_id foreach networks\n",
    "\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "pre_tx_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    tx.block_number,\n",
    "    tx.from_address,\n",
    "    tx.to_address,\n",
    "    tx.gas,\n",
    "    tx.receipt_gas_used as gas_used,\n",
    "    tx.gas_price,\n",
    "    tx.value,\n",
    "    null as token_transfer,\n",
    "    null as token_contract,\n",
    "    ((tx.value / POWER(10, 18)) * cmc_h.open) AS volume,\n",
    "    (tx.receipt_gas_used * tx.gas_price) / POWER(10,18) as gas_spent,\n",
    "    ((tx.receipt_gas_used * tx.gas_price) / POWER(10,18)) * cmc_h.open as gas_spent_usd\n",
    "FROM transactions tx\n",
    "LEFT JOIN cmc_historicals cmc_h \n",
    "    ON (\n",
    "        cmc_h.id = '{cmc_id}'  AND \n",
    "        tx.block_timestamp < timestamp(cmc_h.timestamp) AND \n",
    "        tx.block_timestamp >  timestamp(cmc_h.timestamp - 86400)\n",
    "    )\n",
    "UNION ALL\n",
    "SELECT \n",
    "    tt.block_number,\n",
    "    tt.from_address,\n",
    "    tt.to_address,\n",
    "    tx.gas,\n",
    "    tx.receipt_gas_used as gas_used,\n",
    "    tx.gas_price,\n",
    "    null as value,\n",
    "    tt.value as token_transfer,\n",
    "    tt.token_address,\n",
    "    ((tt.value / POWER(10, t.decimals)) * cmc_h.open) AS volume,\n",
    "    (tx.receipt_gas_used * tx.gas_price) / POWER(10,18) as gas_spent,\n",
    "    ((tx.receipt_gas_used * tx.gas_price) / POWER(10,18)) * native_cmc_h.open as gas_spent_usd\n",
    "FROM token_transfers tt\n",
    "LEFT JOIN transactions tx ON tt.transaction_hash = tx.hash\n",
    "LEFT JOIN tokens t ON LOWER(tt.token_address) = LOWER(t.address)\n",
    "LEFT JOIN cmc_addresses cmc_addr \n",
    "    ON tt.token_address = cmc_addr.{name}\n",
    "LEFT JOIN cmc_historicals cmc_h \n",
    "    ON (\n",
    "        cmc_addr.id = cmc_h.id AND \n",
    "        tx.block_timestamp < timestamp(cmc_h.timestamp) AND \n",
    "        tx.block_timestamp >  timestamp(cmc_h.timestamp - 86400)\n",
    "    )\n",
    "LEFT JOIN cmc_historicals native_cmc_h \n",
    "    ON (\n",
    "        native_cmc_h.id = '{cmc_id}'  AND \n",
    "        tx.block_timestamp < timestamp(native_cmc_h.timestamp) AND \n",
    "        tx.block_timestamp >  timestamp(native_cmc_h.timestamp - 86400)\n",
    "    )\n",
    "\"\"\".format(name = name, cmc_id = cmc_id)) \\\n",
    "    .withColumn('volume', regexp_replace(format_number(\"volume\", 10), \",\", \"\")) \\\n",
    "    .withColumn('gas_spent', regexp_replace(format_number('gas_spent', 10), \",\", \"\")) \\\n",
    "    .withColumn('gas_spent_usd', regexp_replace(format_number('gas_spent_usd', 10), \",\", \"\"))\n",
    "\n",
    "\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53a843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564d4223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.70249104499817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pre_tx_df.repartition(1) \\\n",
    "    .write \\\n",
    "    .option(\"header\",True) \\\n",
    "    .csv(\n",
    "        \"{base_path}/pre_tx/{time_range}/start={start}_end={end}/\" \\\n",
    "            .format(\n",
    "                base_path = base_path, \\\n",
    "                time_range = time_range, \\\n",
    "                start = start, \\\n",
    "                end = end \\\n",
    "            ) \\\n",
    "    )\n",
    "\n",
    "\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd6141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c374c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tx_df.createOrReplaceTempView(\"pre_tx_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203a0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "223e6a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09539031982421875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "tx_volume_df = spark.sql(\"\"\"\n",
    "SELECT from_address as address, SUM(volume) as volume FROM pre_tx_df\n",
    "GROUP BY from_address\n",
    "UNION ALL\n",
    "SELECT to_address as address, SUM(volume) as volume FROM pre_tx_df\n",
    "GROUP BY to_address\n",
    "UNION ALL\n",
    "SELECT token_contract as address, SUM(volume) as volume FROM pre_tx_df\n",
    "GROUP BY token_contract\n",
    "\"\"\").withColumn('volume', regexp_replace(format_number(\"volume\", 10), \",\", \"\"))\n",
    "\n",
    "\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952565b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f58a4968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:>                                                       (0 + 12) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:=>(20 + 5) / 25][Stage 34:>  (0 + 7) / 25][Stage 36:>  (0 + 0) / 25]5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:=>(23 + 2) / 25][Stage 34:> (0 + 10) / 25][Stage 36:>  (0 + 0) / 25]\r",
      "\r",
      "[Stage 32:=>(24 + 1) / 25][Stage 34:> (0 + 11) / 25][Stage 36:>  (0 + 0) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:=>(24 + 1) / 25][Stage 34:> (1 + 11) / 25][Stage 36:>  (0 + 0) / 25]\r",
      "\r",
      "[Stage 32:=>(24 + 1) / 25][Stage 34:>(12 + 11) / 25][Stage 36:>  (0 + 0) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:=>(24 + 1) / 25][Stage 34:=>(22 + 3) / 25][Stage 36:>  (0 + 8) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:===============>(24 + 1) / 25][Stage 36:>               (0 + 11) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/26 08:07:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/07/26 08:07:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.677417993545532"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "tx_volume_df.repartition(1) \\\n",
    "    .write \\\n",
    "    .option(\"header\",True) \\\n",
    "    .csv(\n",
    "        \"{base_path}/tx_volumes/{time_range}/start={start}_end={end}/\" \\\n",
    "            .format(\n",
    "                base_path = base_path, \\\n",
    "                time_range = time_range, \\\n",
    "                start = start, \\\n",
    "                end = end \\\n",
    "            ) \\\n",
    "    )\n",
    "\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4e60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7503624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a2e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
