apiVersion: batch/v1
kind: Job
metadata:
  name: "indexing-pre-tx"
  annotations:
    job.kubernetes.io/dependencies: "indexing"
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  backoffLimit: 10
  ttlSecondsAfterFinished: 100
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: spark-job
          image: 171092530978.dkr.ecr.ap-southeast-1.amazonaws.com/octan/sparkonk8s:0.0.19
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              ephemeral-storage: "100Gi"
            limits:
              ephemeral-storage: "100Gi"
          command:
            - /usr/bin/tini
            - -s
            - --
            - /opt/spark/bin/spark-submit
            - --conf
            - spark.eventLog.dir=s3a://datateam-spark/logs
            - --conf
            - spark.eventLog.enabled=true
            - --conf
            - spark.history.fs.inProgressOptimization.enabled=true
            - --conf
            - spark.history.fs.update.interval=5s
            - --conf
            - spark.kubernetes.container.image=171092530978.dkr.ecr.ap-southeast-1.amazonaws.com/octan/sparkonk8s:0.0.19
            - --conf
            - spark.kubernetes.container.image.pullPolicy=IfNotPresent
            - --conf
            - spark.kubernetes.driver.podTemplateFile=s3a://datateam-spark/driver_pod_template.yml
            - --conf
            - spark.kubernetes.executor.podTemplateFile=s3a://datateam-spark/executor_pod_template.yml
            - --conf
            - spark.dynamicAllocation.enabled=true
            - --conf
            - spark.dynamicAllocation.shuffleTracking.enabled=true
            - --conf
            - spark.dynamicAllocation.maxExecutors=100
            - --conf
            - spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=30
            - --conf
            - spark.dynamicAllocation.executorIdleTimeout=60s
            - --conf
            - spark.driver.memory=4g
            - --conf
            - spark.kubernetes.driver.request.cores=2
            - --conf
            - spark.kubernetes.driver.limit.cores=4
            - --conf
            - spark.executor.memory=8g
            - --conf
            - spark.kubernetes.executor.request.cores=2
            - --conf
            - spark.kubernetes.executor.limit.cores=4
            - --conf
            - spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
            - --conf
            - spark.hadoop.fs.s3a.connection.ssl.enabled=false
            - --conf
            - spark.hadoop.fs.s3a.fast.upload=true
            - --conf
            - spark.serializer=org.apache.spark.serializer.KryoSerializer
            - --conf
            - spark.sql.sources.ignoreDataLocality.enabled=true
            - --conf
            - spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2
            - --conf
            - spark.driver.extraJavaOptions=-Divy.cache.dir=/tmp -Divy.home=/tmp
            - s3a://datateam-spark/bsc-pre-tx.py
